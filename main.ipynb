{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "from tensorflow.keras.applications.vgg19 import VGG19,preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step we define the image path\n",
    "content_path=\"assets/content_file.png\"\n",
    "style_path=\"assets/style_file.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this function is create to get the image from the path and process it before working with it \n",
    "def process_image(path_of_image):\n",
    "    image = load_img(path_of_image)\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    image = np.expand_dims(image,0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(image):\n",
    "    image [:,:,0]+=103.939\n",
    "    image [:,:,1]+=116.779\n",
    "    image [:,:,2]+=123.68\n",
    "    image = image[:,:,::-1]\n",
    "    image = np.clip(image,0,255).astype('uint8')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(image):\n",
    "    if(len(image.shape)==4):\n",
    "        image = np.squeeze(image,axis=0)\n",
    "    image = deprocess_image(image)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = process_image(content_path)\n",
    "style_image = process_image(style_path)\n",
    "\n",
    "display(content_image)\n",
    "display(style_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(A):\n",
    "    channels = int(A.shape[-1])\n",
    "    a = tf.reshape(A,[-1, channels])\n",
    "    gram = tf.matmul(a,a,transpose_a=True)\n",
    "    return gram / tf.cast(tf.shape(a)[0],tf.float32)\n",
    "weight_of_layer = 1. / len(style_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss (content , generated):\n",
    "    map_of_content_image = content_model(content)\n",
    "    map_of_generated_image = content_model(generated)\n",
    "    loss = tf.reduce_mean(tf.square(map_of_content_image-map_of_generated_image))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_cost(style,generated):\n",
    "    J_style = 0\n",
    "    for style_model in style_models:\n",
    "        map_of_style_image = style_model(style)\n",
    "        map_of_generated_image = style_model(generated)\n",
    "        gram_matrix_style_image = gram_matrix(map_of_style_image)\n",
    "        gram_matrix_generated_image = gram_matrix(map_of_generated_image)\n",
    "        content_cost = tf.reduce_mean(tf.square(gram_matrix_style_image-gram_matrix_generated_image))\n",
    "        J_style += content_cost * weight_of_layer\n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG19(include_top=False, weights='imagenet')\n",
    "content_layer = 'block5_conv2'\n",
    "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    outputs = [vgg.get_layer(name).output for name in style_layers]\n",
    "    outputs.append(vgg.get_layer(content_layer).output)\n",
    "    model = tf.keras.Model([vgg.input], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(image, model):\n",
    "    outputs = model(image)\n",
    "    style_features = outputs[:-1]\n",
    "    content_feature = outputs[-1]\n",
    "    return style_features, content_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e3\n",
    "beta = 1e-2\n",
    "\n",
    "def compute_total_loss(content_image, style_image, generated_image, model):\n",
    "    style_features, content_feature = get_features(content_image, model)\n",
    "    generated_style_features, generated_content_feature = get_features(generated_image, model)\n",
    "    \n",
    "    J_content = content_loss(content_feature, generated_content_feature)\n",
    "    J_style = style_cost(style_features, generated_style_features)\n",
    "    J_total = alpha * J_content + beta * J_style\n",
    "    return J_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = tf.Variable(process_image('assets/content_file.png'), dtype=tf.float32)\n",
    "style_image = process_image('assets/style_file.png')\n",
    "content_image = process_image('assets/content_file.png')\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(generated_image, content_image, style_image, model):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_total_loss(content_image, style_image, generated_image, model)\n",
    "    gradients = tape.gradient(loss, generated_image)\n",
    "    optimizer.apply_gradients([(gradients, generated_image)])\n",
    "    generated_image.assign(tf.clip_by_value(generated_image, 0.0, 255.0))\n",
    "    return loss\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = train_step(input_image, content_image, style_image, model)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")\n",
    "        display(input_image.numpy())\n",
    "\n",
    "final_image = input_image.numpy()\n",
    "final_image = deprocess_image(final_image[0])\n",
    "Image.fromarray(final_image).save('stylized_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import vgg19\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to preprocess images for VGG19\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# Function to deprocess images from VGG19 format\n",
    "def deprocess_image(img):\n",
    "    img = img.reshape((img.shape[1], img.shape[2], 3))\n",
    "    img[:, :, 0] += 103.939\n",
    "    img[:, :, 1] += 116.779\n",
    "    img[:, :, 2] += 123.68\n",
    "    img = img[:, :, ::-1]\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Function to load VGG19 model with specific outputs for style and content\n",
    "def get_model():\n",
    "    vgg = vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    style_outputs = [vgg.get_layer(name).output for name in ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']]\n",
    "    content_outputs = [vgg.get_layer('block4_conv2').output]\n",
    "    model_outputs = style_outputs + content_outputs\n",
    "    return tf.keras.models.Model(vgg.input, model_outputs)\n",
    "\n",
    "# Function to calculate style loss\n",
    "def style_loss(style, combination):\n",
    "    style_outputs = get_model()(style)\n",
    "    combination_outputs = get_model()(combination)\n",
    "    style_loss = tf.add_n([tf.reduce_mean((style_outputs[i] - combination_outputs[i])**2) for i in range(len(style_outputs))])\n",
    "    return style_loss\n",
    "\n",
    "# Function to calculate content loss\n",
    "def content_loss(content, combination):\n",
    "    content_outputs = get_model()(content)[-1]\n",
    "    combination_outputs = get_model()(combination)[-1]\n",
    "    content_loss = tf.reduce_mean((content_outputs - combination_outputs)**2)\n",
    "    return content_loss\n",
    "\n",
    "# Parameters and hyperparameters\n",
    "content_image_path = 'assets/content_file.png'\n",
    "style_image_path = 'assets/style_file.png'\n",
    "\n",
    "learning_rate = 10.0\n",
    "epochs = 1000\n",
    "content_weight = 1e3\n",
    "style_weight = 1e-2\n",
    "\n",
    "# Load and preprocess images\n",
    "content_image = preprocess_image(content_path)\n",
    "style_image = preprocess_image(style_path)\n",
    "initial_generated_image = preprocess_image(content_path)\n",
    "generated_image = tf.Variable(initial_generated_image, dtype=tf.float32)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Function to apply gradients and optimize the generated image\n",
    "@tf.function()\n",
    "def train_step(image, content_image, style_image, content_weight, style_weight, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        content_loss_value = content_loss(content_image, image)\n",
    "        style_loss_value = style_loss(style_image, image)\n",
    "        total_loss = content_weight * content_loss_value + style_weight * style_loss_value\n",
    "    gradients = tape.gradient(total_loss, image)\n",
    "    optimizer.apply_gradients([(gradients, image)])\n",
    "    image.assign(tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=255.0))\n",
    "    return total_loss\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = train_step(generated_image, content_image, style_image, content_weight, style_weight, optimizer)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss.numpy()}\")\n",
    "\n",
    "# Convert generated image back to PIL format for saving\n",
    "final_image = deprocess_image(generated_image.numpy())\n",
    "\n",
    "# Save stylized image\n",
    "Image.fromarray(final_image).save('stylized_image.png')\n",
    "\n",
    "# Display final stylized image\n",
    "plt.imshow(final_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import vgg19\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to preprocess images for VGG19\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# Function to deprocess images from VGG19 format\n",
    "def deprocess_image(img):\n",
    "    img = img.reshape((img.shape[1], img.shape[2], 3))\n",
    "    img[:, :, 0] += 103.939\n",
    "    img[:, :, 1] += 116.779\n",
    "    img[:, :, 2] += 123.68\n",
    "    img = img[:, :, ::-1]\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    return img\n",
    "\n",
    "# Function to load VGG19 model with specific outputs for style and content\n",
    "def get_model():\n",
    "    vgg = vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    style_outputs = [vgg.get_layer(name).output for name in ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']]\n",
    "    content_outputs = [vgg.get_layer('block4_conv2').output]\n",
    "    model_outputs = style_outputs + content_outputs\n",
    "    return tf.keras.models.Model(vgg.input, model_outputs)\n",
    "\n",
    "# Function to calculate style loss\n",
    "def style_loss(style, combination):\n",
    "    style_outputs = get_model()(style)\n",
    "    combination_outputs = get_model()(combination)\n",
    "    style_loss = tf.add_n([tf.reduce_mean((style_outputs[i] - combination_outputs[i])**2) for i in range(len(style_outputs))])\n",
    "    return style_loss\n",
    "\n",
    "# Function to calculate content loss\n",
    "def content_loss(content, combination):\n",
    "    content_outputs = get_model()(content)[-1]\n",
    "    combination_outputs = get_model()(combination)[-1]\n",
    "    content_loss = tf.reduce_mean((content_outputs - combination_outputs)**2)\n",
    "    return content_loss\n",
    "\n",
    "# Parameters and hyperparameters\n",
    "content_path = 'assets/content_file.png'\n",
    "style_path = 'assets/style_file.png'\n",
    "\n",
    "learning_rate = 10.0\n",
    "epochs = 1000\n",
    "content_weight = 1e3\n",
    "style_weight = 1e-2\n",
    "\n",
    "# Load and preprocess images\n",
    "content_image = preprocess_image(content_path)\n",
    "style_image = preprocess_image(style_path)\n",
    "initial_generated_image = preprocess_image(content_path)\n",
    "generated_image = tf.Variable(initial_generated_image, dtype=tf.float32)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Function to apply gradients and optimize the generated image\n",
    "@tf.function()\n",
    "def train_step(image, content_image, style_image, content_weight, style_weight, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        content_loss_value = content_loss(content_image, image)\n",
    "        style_loss_value = style_loss(style_image, image)\n",
    "        total_loss = content_weight * content_loss_value + style_weight * style_loss_value\n",
    "    gradients = tape.gradient(total_loss, image)\n",
    "    optimizer.apply_gradients([(gradients, image)])\n",
    "    image.assign(tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=255.0))\n",
    "    return total_loss\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = train_step(generated_image, content_image, style_image, content_weight, style_weight, optimizer)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss.numpy()}\")\n",
    "\n",
    "# Convert generated image back to PIL format for saving\n",
    "final_image = deprocess_image(generated_image.numpy())\n",
    "\n",
    "# Save stylized image\n",
    "Image.fromarray(final_image).save('stylized_image.png')\n",
    "\n",
    "# Display final stylized image\n",
    "plt.imshow(final_image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
